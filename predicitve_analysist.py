# -*- coding: utf-8 -*-
"""Predicitve Analysist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WfLJqSdEZIJZF9WE6xgtstTmHRjpVoE6
"""

#install kaggle
!pip install kaggle

#upload file json

from google.colab import files
files.upload()

#membuat directory kaggle dan dataset
!mkdir ~/.kaggle
!mkdir datasets

#mengganti permission file
!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

#list kaggle dataset
!kaggle datasets list

#download dataset dari kaggle
!kaggle datasets download -d neuromusic/avocado-prices

#unzip dataset yang telah didownload
!unzip /content/avocado-prices -d datasets/

# Commented out IPython magic to ensure Python compatibility.
#import library
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

# load the dataset
op = pd.read_csv('/content/datasets/avocado.csv')
op

"""#Data Understanding



*   Memberikan informasi seperti jumlah data, kondisi data, dan informasi mengenai data yang digunakan 
*   Menuliskan tautan sumber data (https://www.kaggle.com/datasets/neuromusic/avocado-prices/code)
*   Menguraikan seluruh variabel atau fitur pada data.

##keterangan columns pada the dataset:

Date - Tanggal Observasi data

AveragePrice - Harga rata-rata pada satu buah alpukat

type - Konvensional atau organik

year - Tahun

Region - Daerah observasi

Total Volume - Jumlah alpukat yang terjual

4046 - Total jumlah alpukat dengan PLU 4046 terjual

4225 - Total jumlah alpukat dengan PLU 4225 terjual

4770 - Total jumlah alpukat dengan PLU 4770 terjual

##Note
PLU merupakan *Price look-up* nomor berisi 4-5 digit untuk mengidentifikasian suatu produk, berguna untuk memudahkan proses check-out dan juga memudahkan *inventory control*.


"""

#melihat ukuran data pada dataset
op.shape

#melihat informasi dataset
op.info

#melihat nilai numeric dataset
op.describe()

# Datanya belum bertype Date yang kolom Date jadi convert / ubah dulu
op['Date'] = pd.to_datetime(op['Date'])

#melihat informasi dataset
op.info()

# Cek perubahan harga data dari tahun ke tahun
plt.title(f'Data dari tahun ke tahun')
plt.plot(op['AveragePrice'], op['Date'])
plt.show()

# Kita coba cek sebaran dengan cycle per tahun
year = op['Date'].dt.year
year

# melihat nilai unik pada tahun 
year.unique()

#visualisasi data tiap tahun
for y in year.unique():
  plt.title(f'Tahun {y}')
  plt.plot(op[op['Date'].dt.year == y].AveragePrice)
  plt.show()

"""Setelah dilakukan visualisasi """

#visualisasi boxplot 
columns = np.delete(op.columns, 0)
for col in columns:
  plt.title(f'Column {col}')
  sns.boxplot(x="year", y="AveragePrice", data=op)
  plt.show()

# kita drop kolom yang tidak terpakai seperti date dan unnamed
new_op = op.drop('Date', axis=1)
new_op1 = new_op.drop('Unnamed: 0', axis=1)
new_op1

#melihat korelasi matrix
plt.figure(figsize=(10,10))
sns.heatmap(new_op1.corr(), annot=True, cmap='coolwarm',linewidths=0.5)
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)
plt.show()

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(new_op1, diag_kind = 'kde')

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot berdasarkan ukuran kantong
sns.pairplot(new_op1[['Small Bags','Large Bags','XLarge Bags','Total Bags']], plot_kws={"s": 4}, diag_kws=dict(fill=False));

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot berdasarkan jenis PLU
sns.pairplot(new_op1[['4046','4225','4770',]], plot_kws={"s": 4}, diag_kws=dict(fill=False));

"""#Data Preparation

*   Menerapkan dan menyebutkan teknik data preparation yang dilakukan.
*   Teknik yang digunakan pada notebook dan laporan harus berurutan.


*   Menjelaskan proses data preparation yang dilakukan
*   Menjelaskan alasan mengapa diperlukan tahapan data preparation tersebut.



"""

#menunjukan isi dari dataset
new_op1.head()

#untuk melakukan MinMaxScaller kita drop region dan type pada tabel
from sklearn.preprocessing import MinMaxScaler
new_op2 = new_op1.drop('type', axis=1)
new_op3 = new_op2.drop('region', axis=1)

scaler = MinMaxScaler()

final_op = new_op3
scaler.fit(final_op[final_op.columns])
final_op[final_op.columns] = scaler.transform(final_op.loc[:, final_op.columns])

final_op

#melihat deskripsi data
final_op.describe()

# Abis di Standar tinggal di split, jadi data test tinggal tembak aja pake pred
from sklearn.model_selection import train_test_split

X, y = final_op.drop('AveragePrice', axis=1), final_op['AveragePrice']

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=767)

"""#Modeling


*   Membuat model machine learning untuk menyelesaikan permasalahan.

*   Menjelaskan tahapan dan parameter yang digunakan pada proses pemodelan.
*   Menjelaskan kelebihan dan kekurangan dari setiap algoritma yang digunakan.

*   Jika menggunakan satu algoritma pada solution statement, lakukan proses improvement terhadap model dengan hyperparameter tuning. Jelaskan proses improvement yang dilakukan.


*  Jika menggunakan dua atau lebih algoritma pada solution statement, maka pilih model terbaik sebagai solusi. Jelaskan mengapa memilih model tersebut sebagai model terbaik.



"""

#import library
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Siapkan dataframe untuk analisis model
report = pd.DataFrame(index=['train_mse', 'test_mse'], 
                      columns=['GradientBoosting', 'RandomForest', 'XGB', 'LGBM'])

# buat model prediksi
# model Random Forest
# n_estimator = number of tree in the forest
# max_depth = max kedalaman tree
# n_jobs = -1 using all processor
RF = RandomForestRegressor(n_estimators=100, random_state=55, n_jobs=-1)
RF.fit(x_train, y_train)

#Model XGradient boosting
XGB = GradientBoostingRegressor()
XGB.fit(x_train, y_train)

#Model Light GBM
LGBM = LGBMRegressor()
LGBM.fit(x_train, y_train)

#Model GB
GB = GradientBoostingRegressor()
GB.fit(x_train, y_train)

#MOdel KNN
from sklearn.neighbors import KNeighborsRegressor
knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(x_train, y_train)

"""#Evaluation



*   Menyebutkan metrik evaluasi yang digunakan.
*   Menjelaskan hasil proyek berdasarkan metrik evaluasi.

*   Menjelaskan metrik evaluasi yang digunakan untuk mengukur kinerja model. Misalnya, menjelaskan formula metrik dan bagaimana metrik tersebut bekerja.




"""

#menentukan nilai MSE dan R2 pada setiap model
hasil_akhir = {'Model_Name': [], 'mse': [], 'r2': []}
pred = GB.predict(x_test)
mse = mean_squared_error(y_true=y_test, y_pred=pred)
r2 = r2_score(y_test, pred)
hasil_akhir['Model_Name'].append('GB')
hasil_akhir['mse'].append(mse)
hasil_akhir['r2'].append(r2)
pred = LGBM.predict(x_test)
mse = mean_squared_error(y_true=y_test, y_pred=pred)
r2 = r2_score(y_test, pred)
hasil_akhir['Model_Name'].append('LGBM')
hasil_akhir['mse'].append(mse)
hasil_akhir['r2'].append(r2)
pred = RF.predict(x_test)
mse = mean_squared_error(y_true=y_test, y_pred=pred)
r2 = r2_score(y_test, pred)
hasil_akhir['Model_Name'].append('RF')
hasil_akhir['mse'].append(mse)
hasil_akhir['r2'].append(r2)
pred = XGB.predict(x_test)
mse = mean_squared_error(y_true=y_test, y_pred=pred)
r2 = r2_score(y_test, pred)
hasil_akhir['Model_Name'].append('XGB')
hasil_akhir['mse'].append(mse)
hasil_akhir['r2'].append(r2)
pred = knn.predict(x_test)
mse = mean_squared_error(y_true=y_test, y_pred=pred)
r2 = r2_score(y_test, pred)
hasil_akhir['Model_Name'].append('knn')
hasil_akhir['mse'].append(mse)
hasil_akhir['r2'].append(r2)

#melihat hasil dari nilai MSE,R2 pada setiap model
hasil_akhir

#karena angkanya terlalu banyak jadi kita ambil 5 angka dibelakang koma
pd.options.display.float_format = '{:.5f}'.format

#menunjukan hasil akhir dengan tampilan dataframe
hasil_akhir = pd.DataFrame.from_dict(hasil_akhir)
hasil_akhir

#menentukan nilai RMSE
hasil_akhir['rmse'] = np.sqrt(hasil_akhir['mse'])

#menampilkan hasil akhir setelah ditambahkan RMSE
hasil_akhir

#nilai XGB,LGBM GB sama RF sama mse, rmse, r2 nya
model_dict = {'RF': RF, 'XGB': XGB, 'GB': GB, 'LGBM': LGBM, 'knn': knn}
prediksi = x_test.iloc[:180].copy()
pred_dict = {'y_true':y_test[:180]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)
 
pd.DataFrame(pred_dict)

#menampilkan score dari setiap model
print("Accuracy score dari model LGBM              = ", LGBM.score(x_test, y_test))
print("Accuracy score dari model GB                = ", GB.score(x_test, y_test))
print("Accuracy score dari model XGB               = ", XGB.score(x_test, y_test))
print("Accuracy score dari model Random Forest     = ", RF.score(x_test, y_test))
print("Accuracy score dari KNN                     = ", knn.score(x_test, y_test))